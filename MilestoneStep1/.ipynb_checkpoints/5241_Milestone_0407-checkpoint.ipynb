{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KaiaX926/P-MNIST-41milestone/blob/main/5241_Milestone_0407.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsllEUh6f2eQ"
   },
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.9.7 (default, Sep 16 2021, 08:50:36) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyLxh4eAtu0V"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6M0ySzktwp_",
    "outputId": "67ba5861-7c88-4101-8bbf-a36b97e15540"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiaxu/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/Users/kaiaxu/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/kaiaxu/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/kaiaxu/opt/anaconda3/envs/tf2/lib/python3.9/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_MNIST = True # If already download , set as False\n",
    "train_data = torchvision . datasets . MNIST (\n",
    "  root ='./ mnist /',\n",
    "  train = True , # this is training data\n",
    "  # transform = torchvision . transforms . ToTensor () ,\n",
    "  download = DOWNLOAD_MNIST ,\n",
    ")\n",
    "test_data = torchvision . datasets . MNIST ( root ='./ mnist /', train = False )\n",
    "\n",
    "# change the features to numpy\n",
    "X_train = train_data . train_data . numpy ()\n",
    "X_test = test_data . test_data . numpy ()\n",
    "\n",
    "# change the labels to numpy\n",
    "Y_train = train_data . train_labels . numpy ()\n",
    "Y_test = test_data . test_labels . numpy ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_LYOAJuuO3S"
   },
   "source": [
    "# 2.Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z47_RU8LuUkH"
   },
   "source": [
    "## **(a)** \n",
    "Plot one sample in X train. What is the number you see from the 28 Ã— 28 pixel-field? Does it match with the label in Y train?\n",
    "\n",
    "A: Yes. The image of figure 6 has the label as 6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "cKY5nZISuEMy",
    "outputId": "5070780b-399c-40df-f81e-ba383a5a8aaa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_idx = np.random.choice(range(X_train.shape[0]))\n",
    "image = X_train[image_idx]\n",
    "image_class = Y_train[image_idx]\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_train[image_idx].astype(\"uint8\"))\n",
    "plt.title(image_class)\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tWzB2QFwAUM"
   },
   "source": [
    "## **(b)** \n",
    "What is the dimension of X train and X test? Normalize X train and X test such that the value of each element lies in [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rpy7fQguwHHs",
    "outputId": "43479662-5064-432c-f186-bd75e8edf64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5Ku8zCizDl8",
    "outputId": "b45f8b6b-f9cf-4c4f-a5ed-2988b1c79c43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0, 255, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train),np.min(X_train),np.max(X_test),np.min(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9rqowL0wWH5",
    "outputId": "8c86706a-55da-4931-bfce-89a718b3643c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "1.0 0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    return (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "\n",
    "X_train_normalized = normalize(X_train)#/255\n",
    "X_test_normalized = normalize(X_test)#/255\n",
    "\n",
    "print(X_train_normalized.shape, X_test_normalized.shape)\n",
    "print(np.max(X_train_normalized), np.min(X_train_normalized),np.max(X_test_normalized), np.min(X_test_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOUPaegT5QAy"
   },
   "source": [
    "## **(c)** \n",
    "A popular choice to deal with the labels is to use the one-hot embedding. Represent\n",
    "Y train and Y test using one-hot embedding. List the benefit of such transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJp82_g-sWZg",
    "outputId": "47dcd668-0e53-4f1b-c287-9efdacc0ca53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train and test tagert data after one-hot embedding are (60000, 10) and (10000, 10)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "train_labels = enc.fit_transform(Y_train.reshape(-1, 1)).toarray()\n",
    "test_labels = enc.fit_transform(Y_test.reshape(-1, 1)).toarray()\n",
    "print(f'Shapes of train and test tagert data after one-hot embedding are {train_labels.shape} and {test_labels.shape}')\n",
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vh7tOCAy6KrM"
   },
   "source": [
    "1. It eliminates the influence of the numeric value labels in prediction. For example, the computer might assume group 1 is closer to group 2 than to group 9. However, the distance between them is not affected by the group number at all.\n",
    "2. If the tags are strings, one-hot embedding will help transfer the labels into numbers for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zYGTIqUFVgh"
   },
   "source": [
    "# 3. Before Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjMJJRW_FQhi"
   },
   "source": [
    "## **(a)** \n",
    "Try to implement and train the above mentioned classifier on the training\n",
    "dataset, and report the test errors of them using the test dataset. Can you reproduce\n",
    "the results? If not, please justify your reason\n",
    "\n",
    "A: The specific test error cannot be reproduced since the random state is not anchored. The accuracies of KNN and AdaBoost are similar to the output in the paper while the outcome of SVM is a little bit lower than expected. \\\n",
    "I guess it's because:\n",
    "1. There are so many parameters that need to be specified. Since I only have limited computation sources, I cannot search among all the choices and pick the best one.\n",
    "2. The size of data we are using is 28*28 while the original one was 32*32. The \"center-focused\" data may lead to different outcomes compared to the original ones.\n",
    "3. The normalization method I'm using is (x - min) / (max-min). There are other normalization methods or can just divide the value by 255 to achieve a similar output. Different data preprocessing will lead to different accuracy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKodxeo-2ABF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def errorrate(y_pred, y_true):\n",
    "    error = sum([y_pred[i]!=y_true[i] for i in range(len(y_true))])\n",
    "    return error/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NXFLPtEFvsw"
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Tj7pm-lFwy0",
    "outputId": "a98db479-15cf-461d-d4a0-8f32b1d624eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error of KNN is:  [0.0035 0.0066 0.0076 0.0064 0.0073 0.0059 0.0029 0.0079 0.0093 0.0098]\n",
      "Accuracy_score of KNN is:  0.9558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=10)\n",
    "KNN.fit(np.reshape(X_train_normalized,(60000,28*28)),train_labels)\n",
    "knn_prediction = KNN.predict(np.reshape(X_test_normalized,(10000,28*28)))\n",
    "KNN_accuracy = accuracy_score(test_labels, knn_prediction)\n",
    "print('Test Error of KNN is: ', errorrate(knn_prediction,test_labels))\n",
    "print('Accuracy_score of KNN is: ', KNN_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiMjsjjRUeLR"
   },
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD0Z0nEZUede",
    "outputId": "28a32b11-0fc4-4f81-8a7a-9c956e2cd05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error of AdaBoost is:  0.0369\n",
      "Accuracy_score of AdaBoost is:  0.9631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=300)\n",
    "ABC.fit(np.reshape(X_train_normalized,(60000,28*28)),Y_train)\n",
    "abc_prediction = ABC.predict(np.reshape(X_test_normalized,(10000,28*28)))\n",
    "ABC_accuracy = accuracy_score(Y_test, abc_prediction)\n",
    "print('Test Error of AdaBoost is: ', errorrate(abc_prediction,Y_test))\n",
    "print('Accuracy_score of AdaBoost is: ', ABC_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAGv7nVNUUSM"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIM9blYnSS-l",
    "outputId": "b63798cc-e15e-4a6a-c3cf-ea59ef21d1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error of SVM is:  0.0208\n",
      "Accuracy_score of SVM is:  0.9792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM = SVC(kernel='rbf')\n",
    "SVM.fit(np.reshape(X_train_normalized,(60000,28*28)),Y_train)\n",
    "svm_prediction = SVM.predict(np.reshape(X_test_normalized,(10000,28*28)))\n",
    "SVM_accuracy = accuracy_score(Y_test, svm_prediction)\n",
    "print('Test Error of SVM is: ', errorrate(svm_prediction,Y_test))\n",
    "print('Accuracy_score of SVM is: ', SVM_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMWFZpvyaqxO"
   },
   "source": [
    "## **(b)**\n",
    "Pick your favorite classifier (not limited to the above mentioned algorithms)\n",
    "and try to implement it on the training set and report the test error using the test\n",
    "dataset. Turn the hyperparameters until it out perform all three of the classifier you\n",
    "implemented in part 2(a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0X-ogARUPkEy"
   },
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2p-NeHgR_CO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8J6kmAjFw3O",
    "outputId": "8d5e0f22-b6a4-49c8-ffeb-7947612b75b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "# import libraries\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 512\n",
    "        hidden_2 = 512\n",
    "        hidden_3 = 512\n",
    "        hidden_4 = 128\n",
    "        hidden_5 = 64\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(28 * 28, hidden_1)\n",
    "        # linear layer (n_hidden1 -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden2 -> hidden_3)\n",
    "        self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
    "\n",
    "        self.fc5 = nn.Linear(hidden_3, 10)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # add output layer\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwOjWqsmsWZj"
   },
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tewD9dWIsWZj",
    "outputId": "db9193e0-d40d-451e-a823-f71e8cf4ecce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 22.490480  \tTest accuracy 0.869000\n",
      "Epoch: 2 \tTraining Loss: 6.846247  \tTest accuracy 0.912700\n",
      "Epoch: 3 \tTraining Loss: 4.714404  \tTest accuracy 0.937300\n",
      "Epoch: 4 \tTraining Loss: 3.622157  \tTest accuracy 0.947900\n",
      "Epoch: 5 \tTraining Loss: 2.942351  \tTest accuracy 0.954600\n",
      "Epoch: 6 \tTraining Loss: 2.469449  \tTest accuracy 0.961800\n",
      "Epoch: 7 \tTraining Loss: 2.143776  \tTest accuracy 0.965400\n",
      "Epoch: 8 \tTraining Loss: 1.885791  \tTest accuracy 0.967900\n",
      "Epoch: 9 \tTraining Loss: 1.684404  \tTest accuracy 0.971300\n",
      "Epoch: 10 \tTraining Loss: 1.498155  \tTest accuracy 0.971600\n",
      "Epoch: 11 \tTraining Loss: 1.300878  \tTest accuracy 0.972800\n",
      "Epoch: 12 \tTraining Loss: 1.196633  \tTest accuracy 0.972500\n",
      "Epoch: 13 \tTraining Loss: 1.092232  \tTest accuracy 0.973100\n",
      "Epoch: 14 \tTraining Loss: 0.995636  \tTest accuracy 0.975500\n",
      "Epoch: 15 \tTraining Loss: 0.945610  \tTest accuracy 0.975800\n",
      "Epoch: 16 \tTraining Loss: 0.833401  \tTest accuracy 0.975000\n",
      "Epoch: 17 \tTraining Loss: 0.759177  \tTest accuracy 0.976100\n",
      "Epoch: 18 \tTraining Loss: 0.722228  \tTest accuracy 0.975100\n",
      "Epoch: 19 \tTraining Loss: 0.653801  \tTest accuracy 0.977300\n",
      "Epoch: 20 \tTraining Loss: 0.621552  \tTest accuracy 0.975700\n",
      "Epoch: 21 \tTraining Loss: 0.582450  \tTest accuracy 0.977700\n",
      "Epoch: 22 \tTraining Loss: 0.511360  \tTest accuracy 0.979500\n",
      "Epoch: 23 \tTraining Loss: 0.494088  \tTest accuracy 0.976800\n",
      "Epoch: 24 \tTraining Loss: 0.452995  \tTest accuracy 0.977100\n",
      "Epoch: 25 \tTraining Loss: 0.434636  \tTest accuracy 0.977700\n",
      "Epoch: 26 \tTraining Loss: 0.401028  \tTest accuracy 0.977800\n",
      "Epoch: 27 \tTraining Loss: 0.370620  \tTest accuracy 0.978200\n",
      "Epoch: 28 \tTraining Loss: 0.343162  \tTest accuracy 0.977200\n",
      "Epoch: 29 \tTraining Loss: 0.335955  \tTest accuracy 0.979800\n",
      "Epoch: 30 \tTraining Loss: 0.339072  \tTest accuracy 0.978600\n",
      "Epoch: 31 \tTraining Loss: 0.294595  \tTest accuracy 0.979000\n",
      "Epoch: 32 \tTraining Loss: 0.284252  \tTest accuracy 0.978600\n",
      "Epoch: 33 \tTraining Loss: 0.287272  \tTest accuracy 0.980100\n",
      "Epoch: 34 \tTraining Loss: 0.256079  \tTest accuracy 0.979000\n",
      "Epoch: 35 \tTraining Loss: 0.229673  \tTest accuracy 0.978900\n",
      "Epoch: 36 \tTraining Loss: 0.239416  \tTest accuracy 0.980800\n",
      "Epoch: 37 \tTraining Loss: 0.214835  \tTest accuracy 0.980800\n",
      "FINAL Test Error of a CNN is:  tensor(0.0192)\n",
      "FINAL Accuracy_score of a CNN is:  0.9808\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "\n",
    "model.train() # prep model for training\n",
    "cnn_accuracy_summary = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader: #train_loader:train_labels = to_categorical(Y_train)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "             \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "    cnn_prediction = []\n",
    "    for data, target in test_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        cnn_prediction += list(pred)\n",
    "\n",
    "    #cnn_prediction = model.predict(np.reshape(X_test_normalized,(10000,28*28)))\n",
    "    cnn_accuracy = accuracy_score(Y_test, cnn_prediction)\n",
    "    cnn_accuracy_summary.append(cnn_accuracy)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}  \\tTest accuracy {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        cnn_accuracy\n",
    "        ))\n",
    "    \n",
    "    if len(cnn_accuracy_summary) > 3:\n",
    "        if cnn_accuracy_summary[-1] > 0.98 and np.mean(cnn_accuracy_summary[-3:]) > 0.98:#cnn_accuracy_summary[-1] < cnn_accuracy_summary[-3]:\n",
    "            break\n",
    "\n",
    "cnn_accuracy = accuracy_score(Y_test, cnn_prediction)\n",
    "print('FINAL Test Error of a CNN is: ', errorrate(cnn_prediction,Y_test))\n",
    "print('FINAL Accuracy_score of a CNN is: ', cnn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjE6yao4sWZj"
   },
   "source": [
    "I add a simple early stop system to prevent overfitting that stops the training once it's better than the baseline methods since I only have limited computation sources that might explode before I can get the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzHi767_sWZj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5241_Milestone_0407.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
